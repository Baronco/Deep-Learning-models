{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from shutil import copy\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where is all the raw images\n",
    "RAW_PATH = Path(r'D:\\ML Datasets\\kagglecatsanddogs_5340\\PetImages')\n",
    "OUTPUT_PATH = Path(r'D:\\ML Datasets\\kagglecatsanddogs_5340\\Color')\n",
    "OUTPUT_PATH_DEPTH_MAP = Path(r'D:\\ML Datasets\\kagglecatsanddogs_5340\\Depth Map')\n",
    "IMG_FORMAT = 'jpg'\n",
    "SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_crop_resize(raw_img_path, img_name,nominal_size = SIZE, output_path = OUTPUT_PATH, format=IMG_FORMAT, verbose=False):\n",
    "    #load img\n",
    "    image = Image.open(raw_img_path)\n",
    "\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "    # shape\n",
    "    width, height = image.size\n",
    "    if verbose:\n",
    "        print(f'width: {width}, height: {height}')\n",
    "    # resize conditions\n",
    "    if width < nominal_size and nominal_size < height:\n",
    "        if verbose:\n",
    "            print('Resize Case 1')\n",
    "        scale = nominal_size / width\n",
    "        new_image = image.resize((int(width * scale) , int(height * scale) ), Image.LANCZOS)\n",
    "    elif  width > nominal_size and nominal_size > height:\n",
    "        if verbose:\n",
    "            print('Resize Case 2')\n",
    "        scale = nominal_size / height\n",
    "        new_image = image.resize((int(width * scale) , int(height * scale) ), Image.LANCZOS)\n",
    "    elif width < nominal_size and nominal_size > height:\n",
    "        if verbose:\n",
    "            print('Resize Case 3')\n",
    "        scale = nominal_size / min([height,width])\n",
    "        new_image = image.resize((int(width * scale) , int(height * scale) ), Image.LANCZOS)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('Resize Case 4')\n",
    "        new_image = image.copy()\n",
    "\n",
    "    # center coords\n",
    "    width2, height2 = new_image.size\n",
    "    # last tranformation\n",
    "    if (width > nominal_size*1  and width < nominal_size*1.25)  and (height > nominal_size*1 and height < nominal_size*1.25):\n",
    "        new_image = new_image.resize((nominal_size, nominal_size), Image.LANCZOS)\n",
    "        if verbose:\n",
    "            print('Resize Case 5')\n",
    "    else:\n",
    "        crop = new_image.crop(\n",
    "            (width2//2 - nominal_size//2 ,height2//2 - nominal_size//2, width2//2 + nominal_size//2,height2//2 + nominal_size//2)\n",
    "            )\n",
    "        new_image = crop.resize((nominal_size, nominal_size), Image.LANCZOS)\n",
    "        if verbose:\n",
    "            print('Resize Case 6')\n",
    "\n",
    "    # final shape\n",
    "    if verbose:\n",
    "        print(f'Final shape: {new_image.size}')\n",
    "\n",
    "    # # name and format\n",
    "    # if len(str(img_name)) == 1:\n",
    "    #     img_name = f'0{img_name}'\n",
    "    # name\n",
    "    file = f'{img_name}.{format}'\n",
    "\n",
    "    # Save img\n",
    "    new_image.save(\n",
    "        str(\n",
    "            Path(\n",
    "                output_path,\n",
    "                file\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imgs dogs: 12500\n",
      "Total imgs cats: 12500\n"
     ]
    }
   ],
   "source": [
    "list_of_raw_imgs_dogs = glob(\n",
    "    str(\n",
    "        Path(\n",
    "            RAW_PATH,\n",
    "            'Dog',\n",
    "            '*.jpg'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "list_of_raw_imgs_cats = glob(\n",
    "    str(\n",
    "        Path(\n",
    "            RAW_PATH,\n",
    "            'Cat',\n",
    "            '*.jpg'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f'Total imgs dogs: {len(list_of_raw_imgs_dogs)}')\n",
    "print(f'Total imgs cats: {len(list_of_raw_imgs_cats)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  91%|██████████████████▎ | 11411/12500 [00:47<00:04, 255.00it/s]c:\\Users\\jean-\\anaconda3\\envs\\DeepLearningDev\\lib\\site-packages\\PIL\\TiffImagePlugin.py:890: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "Processing: 100%|████████████████████| 12500/12500 [00:51<00:00, 241.52it/s]\n",
      "Processing: 100%|████████████████████| 12500/12500 [00:50<00:00, 248.40it/s]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for path in tqdm(list_of_raw_imgs_dogs, bar_format='{l_bar}{bar:20}{r_bar}', desc = \"Processing\"):\n",
    "    try:\n",
    "        img_crop_resize(\n",
    "            raw_img_path=path, \n",
    "            output_path= str(Path(OUTPUT_PATH,'Dog')),\n",
    "            img_name=count+1,\n",
    "            verbose=False\n",
    "        )\n",
    "        count+=1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "count = 0\n",
    "for path in tqdm(list_of_raw_imgs_cats, bar_format='{l_bar}{bar:20}{r_bar}', desc = \"Processing\"):\n",
    "    try:\n",
    "        img_crop_resize(\n",
    "            raw_img_path=path, \n",
    "            output_path= str(Path(OUTPUT_PATH,'Cat')),\n",
    "            img_name=count+1,\n",
    "            verbose=False\n",
    "        )\n",
    "        count+=1\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(task=\"depth-estimation\", model=\"depth-anything/Depth-Anything-V2-Small-hf\", device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of cropped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imgs dogs: 12499\n",
      "Total imgs cats: 12499\n"
     ]
    }
   ],
   "source": [
    "list_of_raw_imgs_dogs = glob(\n",
    "    str(\n",
    "        Path(\n",
    "            OUTPUT_PATH,\n",
    "            'Dog',\n",
    "            '*.jpg'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "list_of_raw_imgs_cats = glob(\n",
    "    str(\n",
    "        Path(\n",
    "            OUTPUT_PATH,\n",
    "            'Cat',\n",
    "            '*.jpg'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f'Total imgs dogs: {len(list_of_raw_imgs_dogs)}')\n",
    "print(f'Total imgs cats: {len(list_of_raw_imgs_cats)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|████████████████████| 12499/12499 [12:01<00:00, 17.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm(list_of_raw_imgs_dogs, bar_format='{l_bar}{bar:20}{r_bar}', desc = \"Processing\"):\n",
    "    file_name = path[len(str(Path(OUTPUT_PATH,'Dog')))+1 :]\n",
    "    image = Image.open(path)\n",
    "    depth = pipe(image)[\"depth\"]\n",
    "    # Save img\n",
    "    depth.save(\n",
    "        str(\n",
    "            Path(\n",
    "                OUTPUT_PATH_DEPTH_MAP,\n",
    "                'Dog',\n",
    "                file_name\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|████████████████████| 12499/12499 [11:53<00:00, 17.51it/s]\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm(list_of_raw_imgs_cats, bar_format='{l_bar}{bar:20}{r_bar}', desc = \"Processing\"):\n",
    "    file_name = path[len(str(Path(OUTPUT_PATH,'Cat')))+1 :]\n",
    "    image = Image.open(path)\n",
    "    depth = pipe(image)[\"depth\"]\n",
    "    # Save img\n",
    "    depth.save(\n",
    "        str(\n",
    "            Path(\n",
    "                OUTPUT_PATH_DEPTH_MAP,\n",
    "                'Cat',\n",
    "                file_name\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearningDev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
